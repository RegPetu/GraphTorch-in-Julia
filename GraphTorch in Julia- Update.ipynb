{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Pkg; Pkg.add(\"Pkg\")\n",
    "#import Pkg; Pkg.add(\"LightGraphs\")\n",
    "#import Pkg; Pkg.add(\"PyCall\")\n",
    "#import Pkg; Pkg.add(\"MatrixNetworks\")\n",
    "#import Pkg; Pkg.add(\"SparseArrays\")\n",
    "#import Pkg; Pkg.add(\"LinearAlgebra\")\n",
    "#import Pkg; Pkg.add(\"VegaLite\")\n",
    "#import Pkg; Pkg.add(\"MultivariateStats\")\n",
    "#import Pkg; Pkg.add(\"RDatasets\")\n",
    "#import Pkg; Pkg.add(\"TensorOperations\")\n",
    "#import Pkg; Pkg.add(\"Colors\")\n",
    "#import Pkg; Pkg.add(\"GraphPlot\")\n",
    "#import Pkg; Pkg.add(\"SimpleWeightedGraphs\")\n",
    "#import Pkg; Pkg.add(\"DelimitedFiles\")\n",
    "#import Pkg; Pkg.add(\" StatsBase\")\n",
    "#import Pkg; Pkg.add(\"Plots\")\n",
    "#import Pkg; Pkg.add(\"VegaDatasets\")\n",
    "#import Pkg; Pkg.add(\"TSne\")\n",
    "\n",
    "\n",
    "\n",
    "using PyCall\n",
    "using LightGraphs\n",
    "using MatrixNetworks\n",
    "using VegaDatasets\n",
    "using DataFrames\n",
    "using SparseArrays\n",
    "using LinearAlgebra\n",
    "using Plots\n",
    "using VegaLite\n",
    "using TensorOperations\n",
    "using TSne, Colors, GraphPlot, LightGraphs, SimpleWeightedGraphs,DelimitedFiles, StatsBase, Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniform (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function uniform(size, tensor)\n",
    "        if tensor is \n",
    "    not\n",
    "    nothing\n",
    "        \n",
    "    return \n",
    "    bound = 1.0 / math.sqrt(size)\n",
    "    tensor.data.uniform_(-bound, bound) \n",
    "       \n",
    "    end\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function kaiming_uniform(tensor, fan, a)\n",
    "    if tensor is \n",
    "        not \n",
    "        nothing\n",
    "        \n",
    "        return\n",
    "        bound = math.sqrt(6 / ((1 + a^2) * fan))\n",
    "        tensor.data.uniform_(-bound, bound)\n",
    "    end\n",
    "end\n",
    "\n",
    "function glorot(tensor)\n",
    "    if tensor is \n",
    "        not \n",
    "        nothing\n",
    "        \n",
    "        return\n",
    "        stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-1)))\n",
    "        tensor.data.uniform_(-stdv, stdv)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function glorot_orthogonal(tensor, scale)\n",
    "    if tensor is \n",
    "        not \n",
    "        nothing\n",
    "        \n",
    "        return\n",
    "        torch.nn.init.orthogonal_(tensor.data)\n",
    "        scale /= ((tensor.size(-2) + tensor.size(-1)) * tensor.var())\n",
    "        tensor.data *= scale.sqrt()\n",
    "    end\n",
    "end\n",
    "\n",
    "function zeros(tensor)\n",
    "    if tensor is \n",
    "        not\n",
    "        nothing\n",
    "        \n",
    "        return\n",
    "        tensor.data.fill_(0)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function ones(tensor)\n",
    "    if tensor is \n",
    "        not\n",
    "        nothing\n",
    "        \n",
    "        return\n",
    "        tensor.data.fill_(1)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function normal(tensor, mean, std)\n",
    "    if tensor is \n",
    "        not \n",
    "        nothing\n",
    "        \n",
    "        return\n",
    "        tensor.data.normal_(mean, std)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hasproperty (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasproperty(item, s::Symbol) = s in fieldnames(typeof(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_reset (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'r' = 'reset_parameters'\n",
    "function _reset(item)\n",
    "    if hasproperty(item, 'r') \n",
    "        return\n",
    "        item.reset_parameters()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reset (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'c'='children'\n",
    "function reset(nn)\n",
    "    if nn is\n",
    "        not\n",
    "        nothing\n",
    "                \n",
    "        return\n",
    "        if hasproperty(nn, 'c') & len(list(nn.children())) > 0\n",
    "        end\n",
    "        for item in nn.children()\n",
    "            return _reset(item)\n",
    "            end\n",
    "\n",
    "        if not\n",
    "                    hasproperty(nn, 'c') & len(list(nn.children())) > 0\n",
    "                    return\n",
    "                    _reset(nn) \n",
    "        end\n",
    "                    \n",
    "                    function _reset(item)\n",
    "                        if hasproperty(item, 'r') \n",
    "                        return\n",
    "                        item.reset_parameters()\n",
    "                    end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "using TensorOperations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gcn_norm (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using SparseArray, TensorOperations, Linearalgerbra\n",
    "#from torch.nn import Module, Parameter#\n",
    "#from torch import Tensor\n",
    "#from typing import Optional\n",
    "#using glorot\n",
    "\n",
    "function gcn_norm(SparseArray, add_self_loops; bool = True)\n",
    "    if adj.has_value() == False\n",
    "        adj = adj.fill_value(1.)\n",
    "    if add_self_loops\n",
    "        A_tilde = fill_diag(adj, 1)\n",
    "    D_tilde = sum(A_tilde, dim = 1)\n",
    "    D_tilde_inv_sqrt = D_tilde.pow_(-0.5)\n",
    "    D_tilde_inv_sqrt.masked_fill_(D_tilde_inv_sqrt == float('i'), 0)\n",
    "    A_hat = mul(mul(A_tilde, D_tilde_inv_sqrt.unsqueeze(0)), D_tilde_inv_sqrt.unsqueeze(0))\n",
    "    return A_hat\n",
    "        end\n",
    "\n",
    "methods(GCN_layer(Module))\n",
    "    \n",
    "    function __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels, \n",
    "                 add_self_loops; bool = True,\n",
    "                 weight_init = glorot\n",
    "                )\n",
    "        super(GCN_layer, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.add_self_loops = add_self_loops\n",
    "        self.weights = Parameter(data = Tensor(in_channels, out_channels))\n",
    "        weight_init(self.weights)\n",
    "        end\n",
    "end    \n",
    "    function forward(self, X, edges)\n",
    "        A_hat = gcn_norm(adj = edges, \n",
    "                         add_self_loops = self.add_self_loops\n",
    "                        )\n",
    "        out = matmul(A_hat, X) \n",
    "        \n",
    "        return out\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/ollin18/Node2Vec.jl`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Toshiba\\.julia\\environments\\v1.6\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Toshiba\\.julia\\environments\\v1.6\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "] add https://github.com/ollin18/Node2Vec.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 1e-15\n",
    "\n",
    "#struct(node2vec_layer(Module))\n",
    "#end\n",
    "#methods(node2vec_layer(Module))\n",
    "\n",
    "    function __init__(self, graph, node_type)\n",
    "        super(node2vec_layer, self).__init__()\n",
    "        self.w = graph.node_data[node_type]\n",
    "end\n",
    "\n",
    "    \n",
    "    function forward(self, batch)\n",
    "        \"\"\"Returns the embeddings for the nodes in :obj:`batch`.\"\"\"\n",
    "        return embedding(batch, self.w, sparse = True)\n",
    "end\n",
    "    \n",
    "    function loss(self, pos_rw, neg_rw)\n",
    "        r\"\"\"Computes the loss given positive and negative random walks.\"\"\"\n",
    "\n",
    "        # Positive loss.\n",
    "        start, rest = pos_rw[:, 0], pos_rw[:,:].contiguous()\n",
    "\n",
    "        h_start = embedding(start, self.w, sparse = True).view(pos_rw.size(0), 1,\n",
    "                                                          self.w.shape[1])\n",
    "        h_rest = embedding(rest.view(-1), self.w, sparse = True).view(pos_rw.size(0), -1,\n",
    "                                                                 self.w.shape[1])\n",
    "\n",
    "        out = (h_start * h_rest).sum(dim=-1).view(-1)\n",
    "        pos_loss = -log(sigmoid(out) + eps).mean()\n",
    "\n",
    "        # Negative loss.\n",
    "        start, rest = neg_rw[:, 0], neg_rw[:, :].contiguous()\n",
    "\n",
    "        h_start = embedding(start, self.w, sparse = True).view(neg_rw.size(0), 1,\n",
    "                                                          self.w.shape[1])\n",
    "        h_rest = embedding(rest.view(-1), self.w, sparse = True).view(neg_rw.size(0), -1,\n",
    "                                                                 self.w.shape[1])\n",
    "\n",
    "        out = (h_start * h_rest).sum(dim=-1).view(-1)\n",
    "        neg_loss = -log(1 - sigmoid(out) + eps).mean()\n",
    "\n",
    "        return pos_loss + neg_loss\n",
    "    end\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
